---
title: "Chapter 9 - Clustering of Functional Data"
author: "Vanilton Paulo"
date: "2025-08-17"
output: html_document
---

# Clustering Sparse CD4 Counts Data

CD4 immune cells are often collected from a person at irregular intervals.They are not always available for every person at every time point hence sparse observations. When data is sparse, you can not just connect the dots to form a smooth curve for each person because there aren't simply enough points. This makes direct clustering (grouping similar curves together) impossible.

We are going to use `face.sparse` to fill in for all the missing observations.This will help predict the most likely value for a CD4 count at any given time, even if a measurement was not taken. This turns the irregular, sparse data into a complete, smooth function for each individual.\
\
Our goal is to use `tfb_fpc` from **`tidyfun`** here using `face.sparse` as the underlying engine for estimating eigenfunctions and their scores.

```{r setup, echo = TRUE, message = FALSE}
# ─ Packages ───────────────────
#List of required packages
packages <- c(
  "refund",
  "tidyverse",
  "tidyfun",
  "face"
)

#Install missing packages
install_if_missing <- function(pkg) {
  if (!requireNamespace(pkg, quietly = TRUE)) {
    install.packages(pkg)
  }
}

#Install missing packages
invisible(lapply(packages, install_if_missing))



#Load packages
library(refund)      
library(tidyverse)   
library(tidyfun)     
library(face)

#For reproducible results
set.seed(53615)
```

```{r load-data, include = TRUE}
# ─────── Data ──────────────────
#Load the data
data(cd4)
```

```{r helpers,echo=TRUE}
#─────────── Wrap face::face.sparse for use as FPCA method in tfb_fpc ──────────────────

#Purpose:Use tfb_fpc here using face.sparse as the underlying engine for estimating eigenfunctions and their scores.

# Define scoring function (simple weighted LS fit)
# This function was taken from the documentation  of tfb_fpc
  fpca_scores <- function(data_matrix, efunctions, mean, weights) {
    w_mat <- matrix(weights, nrow = nrow(data_matrix), ncol = length(weights), byrow = TRUE)
    w_mat[is.na(data_matrix)] <- 0
    data_matrix[is.na(data_matrix)] <- 0
    data_wc <- t((t(data_matrix) - mean) * sqrt(t(w_mat)))
    t(qr.coef(qr(efunctions), t(data_wc) / sqrt(weights)))
  }

# Define wrapper for face.sparse:
fpca_face_sparse_wrapper <- function(data, arg, pve = 0.995, ...) {
  df <- data.frame(
    y       = data$value,
    argvals = data$arg,
    subj    = data$id
  )
  
  # We are going to run face.sparse
  fit <- face.sparse(
    data= df,
    argvals.new = sort(unique(df$argvals)),
    # We get per-subject FPC scores
    calculate.scores = TRUE,   
    pve = pve,
    ...
  )
  
  # weights for L2-orthonormality & scoring (trapezoid rule on arg grid)
  arg_new <- fit$argvals.new
  w <- c( diff(arg_new), 0 ); w <- (w + c(0, diff(arg_new)))/2  # trapezoid Δ_i
  
  list(
    mu = fit$mu.new,                
    efunctions = fit$eigenfunctions,        
    scores = fit$rand_eff$scores,       
    npc = ncol(fit$eigenfunctions),  
    scoring_function = fpca_scores,    
    arg = arg_new,                   
    weights = w                          
  )
}
```


```{r data-transformation, include = TRUE}
# ─── Data Transformation ─────────────
n <- nrow(cd4)
T <- ncol(cd4)

#Construct a tibble of the data
data <- tibble(
  y = log(as.vector(t(cd4))),
  argvals = rep(-20:40,  times = n),
  subj = rep(seq_len(n), each = T)
) |>
  filter(!is.na(y) & y > 4.5)
```


```{r , include=TRUE}
# ──── FPCA via tfb_fpc, but using FACE under the hood ──────────────────
data <- arrange(data, subj, argvals)

fpca_tf <- tfb_fpc(
  data = data,
  id = "subj",
  arg = "argvals",
  value = "y",
  method = fpca_face_sparse_wrapper,  
  pve = .995 
)
#  tfb[366] on (-20,40) in basis representation:
#  using  2 FPCs 
# 1: (-20,7);(-19,7);(-18,7); ...
# 2: (-20,6);(-19,7);(-18,7); ...
# 3: (-20,7);(-19,7);(-18,7); ...
# 4: (-20,7);(-19,7);(-18,7); ...
# 5: (-20,7);(-19,7);(-18,7); ...
#     [....]   (361 not shown)
```

Perform clustering on predicted functions

```{r kclust, include = TRUE}
# ─── Perform clustering of predicted functions from face.sparse   ──────────────
Pred_mat <- as.matrix(fpca_tf)

set.seed(202200228)
cl_kmeans_CD4 <- kmeans(Pred_mat, centers = 3)
cl_ind_CD4 <- cl_kmeans_CD4$cluster
cl_cen_CD4 <- cl_kmeans_CD4$centers
```

Visualize the results by plotting the predicted CD4 functional curves alongside their corresponding clusters and the estimated cluster centers.

```{r face-sparse-plot, include=TRUE,fig.width=9}
# ─────────── Plot ─────────────────────
# keep cluster levels consistent between curves & centers
curves_tibble <- tibble(
id = 1:length(fpca_tf), 
cluster = factor(cl_ind_CD4),
curve = fpca_tf)


centers_tibble <- tibble(
cluster = factor(1:nrow(cl_cen_CD4)),
centers = tfd(cl_cen_CD4)
)


cluster_colors <- c("1" = "darkred", "2" = "darkorange", "3" = "darkgreen")

ggplot() +
  # individual curves
  geom_spaghetti(
    data = curves_tibble,
    aes(y = curve, group = id, color = cluster),alpha = .10
  ) +
  geom_spaghetti(
    data = centers_tibble,
    aes(y = centers ,color = cluster),alpha = 10
  )+
  scale_color_manual(values = cluster_colors) +
  labs(x = "Time from seroconversion (months)",
       y = "log CD4 counts") +
  theme_classic() +
  theme(
    legend.position = "none",
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 12)
  )

```

# US all-cause excess and Covid-19 mortality

```{r , echo=TRUE,message=FALSE}
# ─ Packages ───────────────────
#List of required packages
packages <- c(
  "refund",
  "tidyverse",
  "tidyfun",
  "scales",
  "usmap",
  "sf",
  "viridis",
  "factoextra",
  "mclust"
)

#Install missing packages
install_if_missing <- function(pkg) {
  if (!requireNamespace(pkg, quietly = TRUE)) {
    install.packages(pkg)
  }
}

#Install missing packages
invisible(lapply(packages, install_if_missing))

library(refund)    
library(tidyfun)   
library(tidyverse)  
library(scales)
library(usmap)
library(sf)
library(viridis)    
library(factoextra)
library(mclust)
```

```{r ,  echo=TRUE, results='hide'}
# ─── Data ────────────────────────────
#Load data
data("COVID19", package = "refund")
names(COVID19)
##  [1] "US_weekly_mort"                      "US_weekly_mort_dates"               
##  [3] "US_weekly_mort_CV19"                 "US_weekly_mort_CV19_dates"          
##  [5] "US_weekly_excess_mort_2020"          "US_weekly_excess_mort_2020_dates"   
##  [7] "US_states_names"                     "US_states_population"               
##  [9] "States_excess_mortality"             "States_excess_mortality_per_million"
## [11] "States_CV19_mortality"               "States_CV19_mortality_per_million"

states <- COVID19$US_states_names
current_date <- COVID19$US_weekly_excess_mort_2020_dates
Wd <- COVID19$States_excess_mortality_per_million
reference_date <- as.Date("2020-01-01")

```

```{r , include=TRUE}
# ──helpers───────────────────
#Converts calendar dates to numeric values 
#The tfd requires numeric values and not as dates values.
num_grid <- function(dates, ref = min(dates)) as.numeric(dates - ref)

num_grid_v2 <- function(dates, ref = as.Date("2020-01-01")) as.numeric(dates - ref)
tnum <- num_grid_v2(current_date)



tf_cluster_kmeans <- function(score_mat, K) {
  km <- kmeans(score_mat, centers = K)
  list(cluster = km$cluster, centers = km$centers)
}

tf_cluster_hclust <- function(score_mat, method = "ward.D2", K = 3) {
  hc <- hclust(dist(score_mat), method = method)
  list(cluster = cutree(hc, k = K), hc = hc)
}

# centres (matrix rows) -> tidyfun curves on a given grid
tf_centers_from_scores <- function(centers_mat, arggrid) {
  tfd(centers_mat, arg = arggrid)
}

# tidyfun helpers (join + plot)
tf_join_clusters_tf <- function(pred_tf, cluster_vec) {
  tibble(
    id      = seq_along(pred_tf),
    cluster = factor(cluster_vec),
    curve   = pred_tf
  )
}

tf_plot_clusters_tf <- function(cluster_tbl, centers_tbl) {
  ggplot() +
    ## highlight centres
    geom_spaghetti(
      data = centers_tbl,
      aes(y = curve, group = cluster),
      colour = "black", linewidth = 1
    ) +
    geom_spaghetti(
      data = centers_tbl,
      aes(y = curve, colour = cluster, group = cluster),
      linewidth = 1
    ) +
    ## individual subjects
    geom_spaghetti(
      data = cluster_tbl,
      aes(y = curve, colour = cluster, group = id),
      alpha = .15, linewidth = .7
    ) +
    scale_color_manual(
      values = c("darkred", "darkorange", "darkgreen"),
      name   = "Cluster"
    ) +
    labs(
      x = "Time from seroconversion (months)",
      y = "Log CD4 counts"
    ) +
    theme_minimal(base_size = 14)
}
```

```{r , include=TRUE,fig.width=9}
# ───Data Transformation ─────────────
#Organize highlighted the states and their curves
df_tibble <- tibble(
  state     = states,
  #the curves
  mortality = tfd(Wd, arg = tnum)  
) %>%
  mutate(
    highlight = if_else(
      state %in% c("New Jersey","Louisiana","California","Maryland","Texas"),
      state, "Other"
    ),
    highlight = factor(highlight, levels = c("Other",
                                             "New Jersey","Louisiana","California","Maryland","Texas"))
  )

## # A tibble: 52 × 3
##    state                                                  mortality highlight 
##    <chr>                                                  <tfd_reg> <fct>     
##  1 Alabama               [1]: ( 3,  0.8);(10,  7.5);(17,-15.2); ... Other     
##  2 Alaska                [2]: ( 3,   -5);(10,   25);(17,    7); ... Other     
##  3 Arizona               [3]: ( 3,   -7);(10,    6);(17,    6); ... Other     
##  4 Arkansas              [4]: ( 3,   -7);(10,   28);(17,   -1); ... Other     
##  5 California            [5]: ( 3,    5);(10,    2);(17,    4); ... California
##  6 Colorado              [6]: ( 3,    3);(10,    7);(17,    4); ... Other     
##  7 Connecticut           [7]: ( 3,  0.3);(10,  0.8);(17,  3.1); ... Other     
##  8 Delaware              [8]: ( 3,   14);(10,   -1);(17,   -9); ... Other     
##  9 District of Columbia  [9]: ( 3,    3);(10,    8);(17,   49); ... Other     
## 10 Florida              [10]: ( 3,    6);(10,   10);(17,    8); ... Other     
## # ℹ 42 more rows

cols <- c(
  "Other"      = "grey85",   
  "New Jersey" = "darkseagreen3",  
  "Louisiana"  = "red",  
  "California" = "plum3",  
  "Maryland"   = "deepskyblue4",  
  "Texas"      = "salmon"   
)

# ─── Plot ────────────────────────────────
#Exploratory plots and analyses

ggplot(df_tibble) +
  geom_spaghetti(aes(y = mortality, colour = highlight, group = state),alpha =0.6) +
  scale_colour_manual(values = cols, name = "States") +
  scale_x_continuous(
    name = "Weeks starting January 2020",
    breaks = as.numeric(seq(reference_date, as.Date("2021-01-01"), by = "3 months") - reference_date),
    labels = format(seq(reference_date, as.Date("2021-01-01"), by = "3 months"), "%b %Y")
  ) +
  labs(y = "US states weekly excess deaths / million") +
  theme_minimal()

```

Mean and median calculations provide essential summary statistics and are a key part of exploratory data analysis, helping to numerically describe the central tendency of eexcess mortality rate per one million residents for several weeks across 52 states and territories.Thus a complement and help to interpret the visual patterns seen in scatterplots.

```{r , include=TRUE}
# ────────── Summary of Analysis──────────────────────
Wd_tfd <- tfd(Wd, arg = tnum)  
# Extract values at week 10 for all states
week10_vals <- Wd_tfd[, tnum[10]]

mean_week10   <- mean(week10_vals, na.rm = TRUE)
## [1] 3.302119
median_week10 <- median(week10_vals, na.rm = TRUE)
## [1] 2.626611
```

On March 7, 2020 (week 10), the excess mortality rate was 3.3 deaths per million on average, with a median of 2.63 deaths per million.

```{r , include=TRUE}
week10 <- Wd[, 10]
ind_out <- which.max(week10_vals)
# Get the name of that state
state_out <- states[ind_out]
val_out <- round(Wd_tfd[ind_out, tnum[6:14]], 1)
```

An outlier was observed in North Dakota on week 10. The state's excess mortality rates from weeks 6 to 14 were: 10.5, -17, 49.7, 10.5, 70.6, 39.2, 6.5, -30.1, -41.8 excess mortality.

Identify the five states with the highest weekly excess mortality rates on week 20.

```{r , include=TRUE}
# ---- Top 5 states at week 20 ----
vals20 <- Wd_tfd[, tnum[20]]
ord20  <- order(vals20)
topweek20 <- round(vals20[ord20][48:52], 1)
states_top_20 <- states[ord20][48:52]
```

For week 20, the five states with the highest excess mortality rates per million residents were the District of Columbia (136.1), Massachusetts (122.1), Delaware (114.5), Connecticut (106.3), and New Jersey (104.5), in descending order.

Identify the five states with the highest weekly excess mortality rates on week 30.

```{r , include=TRUE}
# ---- Top 5 states at week 30 ----
vals30 <- Wd_tfd[, tnum[30]]
ord30  <- order(vals30)
topweek30 <- round(vals30[ord30][48:52], 1)
states_top_30 <- states[ord30][48:52]
```

For week 30, the five states with the highest excess mortality rates per million residents were Mississippi (119.3), Arizona (107), Texas (88.8), Louisiana (87), and South Carolina (84.7), in descending order.

Identify the five states with the highest weekly excess mortality rates on week 40.

```{r , include=TRUE}
# ---- Top 5 states at week 40 ----
vals40 <- Wd_tfd[, tnum[40]]
ord40  <- order(vals40)
topweek40 <- round(vals40[ord40][48:52], 1)
states_top_40 <- states[ord40][48:52]
```

For week 40, the five states with the highest excess mortality rates per million residents were North Dakota (75.8), Arkansas (72.3), the District of Columbia (58.9), Missouri (58.4), and Wyoming (53.2), in descending order.

### K-means clustering of the functional data

```{r , include=TRUE,fig.width=9,message=FALSE}
# ──────────────── K-means clustering of the functional data ──────────────────────────────

rownames(Wd) <- states
set.seed(1000)
km    <- kmeans(Wd, centers = 3)
cl_ind <- km$cluster
cl_cen <- km$centers



##  ─── Build tidyfun objects ──────────────────────
pred_tf <- tfd(Wd, arg = tnum)

centers_tf <- tfd(cl_cen, arg = tnum)

# Create tibbles
cluster_tbl <- tf_join_clusters_tf(pred_tf, cl_ind)
centers_tbl <- tibble(
  cluster = factor(seq_len(nrow(cl_cen))),
  curve   = centers_tf
)

# Plot with corrected date handling
tf_plot_clusters_tf(cluster_tbl, centers_tbl) +
  scale_color_manual(
    values = c("#AA00FF","green", "#FF6D00"),
    name   = "Cluster"
  ) +
  scale_x_continuous(
    breaks = function(x) {
      # Use 2020-01-01 as reference for quarterly breaks
      reference_date <- as.Date("2020-01-01")
      start_date <- reference_date  # Start from Jan 1, 2020
      end_date <- max(current_date)
      quarterly_dates <- seq(from = start_date, to = end_date, by = "3 months")
      # Convert to your numeric scale (days since 2020-01-01)
      as.numeric(quarterly_dates - reference_date)
    },
    labels = function(x) {
      # Convert back to dates using 2020-01-01 as reference
      reference_date <- as.Date("2020-01-01")
      d <- reference_date + x
      format(d, "%b %Y")
    },
    name = "Weeks starting January 2020"
  ) +
  labs(
    y = "Excess mortality per million",
    title = "K-Means Clustering of State Excess-Mortality Curves"
  ) +
  theme_minimal(base_size = 14)
```

```{r , include=TRUE}
##  ─── US MAP PLOT ──────────────────────

# color per group as per the book
colset <- c(rgb(0.41, 0.05, 0.68), rgb(0, 1, 0), rgb(1, .55, 0))

## load state date which contains FIPS code
data("statepop")

## create a data frame to plot based on the input requirement
state_cluster <- data.frame(full = names(cl_ind), cluster = unname(cl_ind))
data_cluster <- statepop %>%
  left_join(state_cluster, by = "full") %>%
  select(fips, cluster)
data_cluster$cluster <- as.factor(data_cluster$cluster)

## make the US map
 plot_usmap(regions = "states", data = data_cluster, values = "cluster") +
  scale_fill_manual(name = "Cluster", values = colset) +
  labs(title = "") +
  theme(legend.position = "right", 
        plot.title = element_text(hjust = 0.5, face = "bold"))


# Start with default state centers
state_centers <- data.frame(
  state = tolower(state.name),
  lon = state.center$x,
  lat = state.center$y
)


# Modify locations for Alaska and Hawaii (inset display)
state_centers <- state_centers %>%
  mutate(
    lon = case_when(
      state == "alaska" ~ -116,
      state == "hawaii" ~ -103,
      TRUE ~ lon
    ),
    lat = case_when(
      state == "alaska" ~ 28,
      state == "hawaii" ~ 28,
      TRUE ~ lat
    )
  )

# Add Distric of Columbia and Puerto Rico
state_centers <- rbind(
  state_centers,
  data.frame(state = "district of columbia", lon = -77.03, lat = 38.89),
  data.frame(state = "puerto rico", lon = -108, lat = 30)
)



# Rename for join
state_centers <- state_centers %>%
  rename(region = state)
# ──────────────── Join Plot Data ───────────────────────────────

state_plot_df <- tibble(
  state   = tolower(states),
  curve   = pred_tf,
  cluster = factor(cl_ind)
) %>%
  left_join(state_centers, by = c("state" = "region"))

# ──────────────── US Map with Glyphs ───────────────────────────────

# ──────────────── US Map with Glyphs (Fixed) ───────────────────────────────

# Use usmap's state outlines
us_map_df <- us_map("states")



# Convert state_plot_df to sf object and transform to match us_map_df
state_plot_sf <- state_plot_df %>%
  st_as_sf(coords = c("lon", "lat"), crs = 4326) %>%  # WGS84 (lat/lon)
  st_transform(st_crs(us_map_df)) %>%  # Transform to match us_map_df projection
  # Extract transformed coordinates
  mutate(
    x_proj = st_coordinates(.)[,1],
    y_proj = st_coordinates(.)[,2]
  ) %>%
  st_drop_geometry()  # Remove geometry column to work with regular dataframe

 ggplot() +
  # First add the map layer using geom_sf
  geom_sf(data = us_map_df,
          fill = "white",
          color = "black",
          size = 0.2) +
  # Then add the functional data glyphs using transformed coordinates
  geom_capellini(data = state_plot_sf,
                 aes(x = x_proj, y = y_proj, tf = curve, colour = cluster),
                 width = 300000, height = 400000, line.linetype = 1) +  # Adjusted size for projected coords
  scale_color_manual(values = c("#AA00FF", "green", "#FF6D00"), name = "Cluster") +
  coord_sf() +
  theme_minimal() +
  labs(title = "US States Excess Mortality Curves with Cluster Colors",
       # or just "Longitude"
       x = "Longitude (°)",  
       ,# or just "Latitude"
       y = "Latitude (°)" )

```

### Hierarchical clustering of functional data
```{r , warning = FALSE, include = TRUE, fig.width = 8, fig.height = 7}
# ── Hierarchical clustering of functional data ───────────────

# Calculate the matrix of distances
dist_matrix <- dist(Wd[,])^2

# Hierarchical clustering on the square Euclidian distances
hc <- hclust(dist_matrix, method = "ward.D2")

# ─── plot  ───────────

fviz_dend(hc,
          k = 5,
          rect = TRUE,  
          rect_fill  = FALSE, 
          k_colors = c("#E69A8DFF", "#F6D55C", "#2A9D8F", "#5F4B8BFF", "#ee7600"),
          lwd = 1,         
          cex = 0.5,         
          main = "Hierarchical clustering on the square Euclidian distances",
          xlab = "Observations",
          ylab = "Distance (Ward.D2)",
          ggtheme = theme_minimal())+
  scale_y_continuous(labels = function(x) {
            ifelse(x == 0, "0", paste0(scales::comma(x/1000), "K"))
          })
```



```{r , include=TRUE, fig.width=7,fig.height=7}
# ─── Hierarchical clustering ────────────────────
rownames(Wd) <- states

# the 52 states in dendrogram order
state_order <- rownames(Wd)[hc$order]

# for each state, its position in that order
row_order_vec  <- match(states, state_order)        

# ─── Build tidyfun tibble ───────────────────────────────────────────────────
#this results in a tibble where each state has its own curve
df_tf <- tibble(
  state = states,
  # wrap  52-length vectors as tfd as per usual
  mortality = tfd(Wd, arg = tnum),   
  # numeric: 1–52 in cluster order
  row_order = row_order_vec          
)
## # A tibble: 52 × 3
##    state                                                  mortality row_order
##    <chr>                                                  <tfd_reg>     <int>
##  1 Alabama               [1]: ( 3,  0.8);(10,  7.5);(17,-15.2); ...        19
##  2 Alaska                [2]: ( 3,   -5);(10,   25);(17,    7); ...         5
##  3 Arizona               [3]: ( 3,   -7);(10,    6);(17,    6); ...        18
##  4 Arkansas              [4]: ( 3,   -7);(10,   28);(17,   -1); ...        36
##  5 California            [5]: ( 3,    5);(10,    2);(17,    4); ...        33
##  6 Colorado              [6]: ( 3,    3);(10,    7);(17,    4); ...        45
##  7 Connecticut           [7]: ( 3,  0.3);(10,  0.8);(17,  3.1); ...        40
##  8 Delaware              [8]: ( 3,   14);(10,   -1);(17,   -9); ...        51
##  9 District of Columbia  [9]: ( 3,    3);(10,    8);(17,   49); ...        39
## 10 Florida              [10]: ( 3,    6);(10,   10);(17,    8); ...        15
## # ℹ 42 more rows

# ─── Plot  ───────────────────────────────────────────────────


# Replicate the original's color strategy
breaks_orig <- c(-50, seq(-40, 130, by = 1), 200, 250, 300)
colors_orig <- viridis::plasma(length(breaks_orig))

gglasagna(
  df_tf,
  tf = mortality,
  order = row_order,
  label = state
) +
  scale_fill_gradientn(
    colors = colors_orig,
    values = scales::rescale(breaks_orig),
    breaks = c(-50, 0, 50, 100, 150, 200, 250, 300),
    limits = c(-50, 300),
    name = "EMR"
  ) +
  #this was the buggy code
  guides(color = "none") +  
  scale_x_continuous(
    name   = "Weeks starting january 2020",
    breaks = num_grid(current_date),
    labels = seq_along(current_date)
  )+
  labs(
    title = "Heatmap of 2020 Weekly Excess Mortality\nStates ordered by hierarchical clustering",
    caption = ""
  ) +
  theme_minimal(base_size = 12) +
  theme(
    #axis.text.y = element_text(size = 6),
    axis.text.x = element_text(size = 6, angle = 90, vjust = 0.5, hjust=1),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank()
  )
```


```{r , include=TRUE}
cut_wardd2 <- cutree(hc, k = 5)

# Get the order of clusters as they appear in the dendrogram (left to right)
dend_order <- hc$order
cluster_first_appearance <- sapply(1:5, function(k) {
  which(dend_order %in% which(cut_wardd2 == k))[1]
})
cluster_reorder <- rank(cluster_first_appearance)

# Relabel clusters based on dendrogram order
relabeled_clusters <- cluster_reorder[cut_wardd2]

clust.col <- c("#E69A8DFF", "#F6D55C", "#2A9D8F", "#5F4B8BFF", "#ee7600")
#cluster_names <- c("Early Peak", "Sustained High", "Late Peak", "Moderate", "Low Impact")


state_cluster <- data.frame(
  full = names(cut_wardd2), 
  cluster = relabeled_clusters#,
  #cluster_name = cluster_names[relabeled_clusters]
)

## load state date which contains FIPS code
data("statepop")
data_cluster <- statepop %>%
  left_join(state_cluster, by = "full") %>%
  select(fips, cluster#, cluster_name
         ) %>%
  mutate(cluster = as.factor(cluster))


# ─── Plot  ───────────────────────────────────────────────────

plot_usmap(regions = "states", data = data_cluster, values = "cluster") +
  scale_fill_manual(
    name = "Cluster", 
    values = clust.col#,
    #labels = cluster_names
  ) +
  labs(
    title = "COVID-19 Excess Mortality Clusters",
    subtitle = "States grouped by temporal mortality patterns"
  ) +
  theme(
    legend.position = "bottom",
    legend.title = element_text(size = 12, face = "bold"),
    legend.text = element_text(size = 10),
    plot.title = element_text(hjust = 0.5, face = "bold", size = 16),
    plot.subtitle = element_text(hjust = 0.5, size = 12)
  ) +
  guides(fill = guide_legend(nrow = 1))

```


```{r , include=TRUE}
# Relabel clusters for consistent order
dend_order <- hc$order
cluster_first_appearance <- sapply(1:5, function(k) {
  which(dend_order %in% which(cut_wardd2 == k))[1]
})
cluster_reorder <- rank(cluster_first_appearance)
relabeled_clusters <- cluster_reorder[cut_wardd2]

# Create cluster mapping
# Fix 1: Make sure both data frames have lowercased state names
state_cluster <- tibble(
  state = tolower(states),  # ⬅️ lowercase to match df_tf
  cluster = factor(relabeled_clusters)
)



state_centers <- data.frame(
  state = tolower(state.name),
  lon = state.center$x,
  lat = state.center$y
)

# Adjust Hawaii and Alaska for inset layout
state_centers <- state_centers %>%
  mutate(
    lon = case_when(
      state == "alaska" ~ -116,
      state == "hawaii" ~ -103,
      TRUE ~ lon
    ),
    lat = case_when(
      state == "alaska" ~ 28,
      state == "hawaii" ~ 28,
      TRUE ~ lat
    )
  )

# Add DC and Puerto Rico
state_centers <- rbind(
  state_centers,
  data.frame(state = "district of columbia", lon = -77.03, lat = 38.89),
  data.frame(state = "puerto rico", lon = -108, lat = 30)
) %>%
  rename(region = state)



# Functional curves already in df_tf
# Merge with cluster info and centroid coordinates
state_plot_df <- df_tf %>%
  mutate(state = tolower(state)) %>%
  left_join(state_cluster, by = c("state")) %>%
  left_join(state_centers, by = c("state" = "region"))




# Base map
us_map_df <- usmap::us_map("states")

# Convert to sf and project to match US map projection
state_plot_sf <- state_plot_df %>%
  st_as_sf(coords = c("lon", "lat"), crs = 4326) %>%  # WGS84
  st_transform(st_crs(us_map_df)) %>%
  mutate(
    x_proj = st_coordinates(.)[,1],
    y_proj = st_coordinates(.)[,2]
  ) %>%
  st_drop_geometry()




cluster_colors <- c("#E69A8DFF", "#F6D55C", "#2A9D8F", "#5F4B8BFF", "#ee7600")

ggplot() +
  geom_sf(data = us_map_df,
          fill = "white",
          color = "black",
          size = 0.2) +
  
  geom_capellini(data = state_plot_sf,
                 aes(x = x_proj, y = y_proj, tf = mortality, colour = cluster),
                 width = 300000, height = 400000,
                 line.linetype = 1, alpha = 2) +
  
  scale_color_manual(values = cluster_colors, name = "Cluster") +
  coord_sf() +
  theme_minimal(base_size = 12) +
  labs(
    title = "US States Excess Mortality Curves with Cluster Colors",
    x = "Longitude (°)",
    y = "Latitude (°)"
  ) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    legend.position = "right"
  )

```

### Distributional clustering

```{r , include=TRUE}
# ─── Distributional clustering ───────────────────────────────────────────────────

# Set color palette
cluster_colors <- c("#E69A8DFF", "#F6D55C", "#2A9D8F", "#5F4B8BFF")

# Center and scale data
X_scaled <- scale(Wd) %>% as.data.frame()

# Fit Gaussian Mixture Model using BIC
bic <- mclustBIC(X_scaled)
gmm_model <- Mclust(X_scaled, x = bic)
clusters <- gmm_model$classification

# Merge clustering results with state population data
state_clusters <- data.frame(full = names(cut_wardd2), cluster = clusters)

data_cluster <- statepop %>%
  left_join(state_clusters, by = "full") %>%
  mutate(cluster = factor(cluster)) %>%
  select(fips, cluster)

# Plot the US map
 plot_usmap(regions = "states", data = data_cluster, values = "cluster") +
  scale_fill_manual(name = "Cluster", values = cluster_colors) +
  labs(title = "") +
  theme(
    legend.position = "right",
    plot.title = element_text(hjust = 0.5, face = "bold")
  )

# Print the map with adjusted margins
par(mar = c(4, 4, 1, 1))

```


```{r , include=TRUE}
library(mclust)

X <- scale(Wd)

# Get BIC and fit GMM
BIC <- mclustBIC(X)
mod <- Mclust(X, x = BIC)

# Get 4-cluster result
res <- mod$classification

# Use same state name vector and lowercase for joining
state_cluster <- tibble(
  state = tolower(names(res)),
  cluster = factor(res)
)


state_centers <- data.frame(
  state = tolower(state.name),
  lon = state.center$x,
  lat = state.center$y
) %>%
  mutate(
    lon = case_when(
      state == "alaska" ~ -116,
      state == "hawaii" ~ -103,
      TRUE ~ lon
    ),
    lat = case_when(
      state == "alaska" ~ 28,
      state == "hawaii" ~ 28,
      TRUE ~ lat
    )
  ) %>%
  rbind(
    data.frame(state = "district of columbia", lon = -77.03, lat = 38.89),
    data.frame(state = "puerto rico", lon = -108, lat = 30)
  ) %>%
  rename(region = state)


df_tf <- tibble(
  state = tolower(states),
  mortality = tfd(Wd, arg = tnum)
)


state_plot_df <- df_tf %>%
  left_join(state_cluster, by = "state") %>%
  left_join(state_centers, by = c("state" = "region"))



library(sf)
library(usmap)

us_map_df <- usmap::us_map("states")

state_plot_sf <- state_plot_df %>%
  st_as_sf(coords = c("lon", "lat"), crs = 4326) %>%
  st_transform(st_crs(us_map_df)) %>%
  mutate(
    x_proj = st_coordinates(.)[,1],
    y_proj = st_coordinates(.)[,2]
  ) %>%
  st_drop_geometry()



colset <- c("#E69A8DFF", "#F6D55C", "#2A9D8F", "#5F4B8BFF")

ggplot() +
  geom_sf(data = us_map_df, fill = "white", color = "black", size = 0.2) +
  
  geom_capellini(
    data = state_plot_sf,
    aes(x = x_proj, y = y_proj, tf = mortality, colour = cluster),
    width = 300000, height = 400000, line.linetype = 1
  ) +
  
  scale_color_manual(values = colset, name = "Cluster") +
  coord_sf() +
  theme_minimal(base_size = 12) +
  labs(
    title = "US States: Model-Based Clustering of Excess Mortality Curves",
    subtitle = "Gaussian Mixture Model (Mclust) with 4 clusters",
    x = "Longitude", y = "Latitude"
  ) +
  theme(
    legend.position = "right",
    plot.title = element_text(hjust = 0.5, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5)
  )
```




### Clustering functional data

```{r , include=TRUE}
# ────────── Clustering functional data ────────────────────────────────

# 
reference_date <- as.Date("2020-01-01")
# tnum <- as.numeric(current_date - reference_date)

t <- 1:dim(Wd)[2]

#Apply functional PCA using the FACE approach
results <- fpca.face(Y = Wd, Y.pred = Wd, center = TRUE, argvals = t,
                     knots = 35, pve = 0.99, var = TRUE)


# Transpose eigenfunctions to PC x time
Phi_t <- t(results$efunctions[, 1:3])


explained <- results$evalues[1:3] / sum(results$evalues)
pc_labels <- paste0("PC", 1:3, " (", round(100 * explained, 1), "%)")

# ─── Build tidy tibble( using tfd) ────────────────────────────────
#At the end we have three curves

pc_df <- tibble(
  pc = factor(pc_labels, levels = pc_labels),
  efun = tfd(Phi_t, arg = tnum)
)

# ─── Plot ────────────────────────────────
ggplot(pc_df, aes(y = efun, color = pc)) +
  geom_spaghetti(alpha = 1) +
  scale_x_continuous(
    name = "Weeks starting January 2020",
    breaks = as.numeric(seq(reference_date, as.Date("2021-01-01"), by = "3 months") - reference_date),
    labels = format(seq(reference_date, as.Date("2021-01-01"), by = "3 months"), "%b %Y")
  ) +
  labs(
    y = "Eigenfunctions",
    color = NULL
  ) +
  theme_classic() +
  theme(
    legend.position = "right",
    legend.text = element_text(size = 12),
    axis.title = element_text(size = 13),
    axis.text = element_text(size = 11)
  )

```