---
title: "Chapter 9 "
author: "Vanilton Paulo"
date: "2025-08-17"
output: html_document
---

# Clustering of Functional Data


## Clustering Sparse CD4 Counts Data

CD4 immune cells are often collected from a person at irregular intervals.They are not always available for every person at every time point hence sparse observations. When data is sparse, you can not just connect the dots to form a smooth curve for each person because there aren't simply enough points. This makes direct clustering (grouping similar curves together) impossible.

We are going to use `face.sparse` to fill in for all the missing observations.This will help predict the most likely value for a CD4 count at any given time, even if a measurement was not taken. This turns the irregular, sparse data into a complete, smooth function for each individual.\
\
Our goal is to use `tfb_fpc` from **`tidyfun`** here using `face.sparse` as the underlying engine for estimating eigenfunctions and their scores.

```{r setup, echo = TRUE, message = FALSE}
# ─ Packages ───────────────────
# List of required packages
packages <- c(
  "refund",
  "tidyverse",
  "tidyfun",
  "face"
)

# Install missing packages
install_if_missing <- function(pkg) {
  if (!requireNamespace(pkg, quietly = TRUE)) {
    install.packages(pkg)
  }
}

# Install missing packages
invisible(lapply(packages, install_if_missing))



# Load packages
library(refund)      
library(tidyverse)   
library(tidyfun)     
library(face)

# For reproducible results
set.seed(53615)
```

```{r load-data, include = TRUE}
# ─────── Data ──────────────────
#Load the data
data(cd4)
```

```{r motor, echo = TRUE}
#─────────── Wrap face::face.sparse for use as FPCA method in tfb_fpc ──────────────────

#Purpose:Use tfb_fpc here using face.sparse as the underlying engine for estimating eigenfunctions and their scores.

# Define scoring function (simple weighted LS fit)
# This function was taken from the documentation  of tfb_fpc
  fpca_scores <- function(data_matrix, efunctions, mean, weights) {
    w_mat <- matrix(weights, nrow = nrow(data_matrix), ncol = length(weights), byrow = TRUE)
    w_mat[is.na(data_matrix)] <- 0
    data_matrix[is.na(data_matrix)] <- 0
    data_wc <- t((t(data_matrix) - mean) * sqrt(t(w_mat)))
    t(qr.coef(qr(efunctions), t(data_wc) / sqrt(weights)))
  }

# Define wrapper for face.sparse
fpca_face_sparse_wrapper <- function(data, arg, pve = 0.995, ...) {
  df <- data.frame(
    y       = data$value,
    argvals = data$arg,
    subj    = data$id
  )
  
  # We are going to run face.sparse
  fit <- face.sparse(
    data= df,
    argvals.new = sort(unique(df$argvals)),
    # We get per-subject FPC scores
    calculate.scores = TRUE,   
    pve = pve,
    ...
  )
  
  # weights for L2-orthonormality & scoring (trapezoid rule on arg grid)
  arg_new <- fit$argvals.new
  w <- c( diff(arg_new), 0 ); w <- (w + c(0, diff(arg_new)))/2  # trapezoid Δ_i
  
  list(
    mu = fit$mu.new,                
    efunctions = fit$eigenfunctions,        
    scores = fit$rand_eff$scores,       
    npc = ncol(fit$eigenfunctions),  
    scoring_function = fpca_scores,    
    arg = arg_new,                   
    weights = w                          
  )
}
```


```{r data-transformation, include = TRUE}
# ─── Data Transformation ─────────────
n <- nrow(cd4)
T <- ncol(cd4)

# Construct a tibble of the data
data <- tibble(
  y = log(as.vector(t(cd4))),
  argvals = rep(-20:40,  times = n),
  subj = rep(seq_len(n), each = T)
) |>
  filter(!is.na(y) & y > 4.5)
```


```{r fpca-tfb, include = TRUE}
# ──── FPCA via tfb_fpc, but using FACE under the hood ──────────────────
data <- arrange(data, subj, argvals)

fpca_tf <- tfb_fpc(
  data = data,
  id = "subj",
  arg = "argvals",
  value = "y",
  method = fpca_face_sparse_wrapper,  
  pve = .995 
)
#  tfb[366] on (-20,40) in basis representation:
#  using  2 FPCs 
# 1: (-20,7);(-19,7);(-18,7); ...
# 2: (-20,6);(-19,7);(-18,7); ...
# 3: (-20,7);(-19,7);(-18,7); ...
# 4: (-20,7);(-19,7);(-18,7); ...
# 5: (-20,7);(-19,7);(-18,7); ...
#     [....]   (361 not shown)
```

Perform clustering on predicted functions

```{r kclust, include = TRUE}
# ─── Perform clustering of predicted functions from face.sparse   ──────────────
Pred_mat <- as.matrix(fpca_tf)

set.seed(202200228)
cl_kmeans_CD4 <- kmeans(Pred_mat, centers = 3)
cl_ind_CD4 <- cl_kmeans_CD4$cluster
cl_cen_CD4 <- cl_kmeans_CD4$centers
```

Visualize the results by plotting the predicted CD4 functional curves alongside their corresponding clusters and the estimated cluster centers.

```{r face-sparse-plot, include = TRUE, fig.width = 9}
# ─────────── Plot ─────────────────────
# keep cluster levels consistent between curves & centers
curves_tibble <- tibble(
id = 1:length(fpca_tf), 
cluster = factor(cl_ind_CD4),
curve = fpca_tf)


centers_tibble <- tibble(
cluster = factor(1:nrow(cl_cen_CD4)),
centers = tfd(cl_cen_CD4)
)


cluster_colors <- c("1" = "darkred", "2" = "darkorange", "3" = "darkgreen")

 ggplot() +
  geom_spaghetti(
    data = curves_tibble,
    aes(y = curve, group = id, color = cluster),alpha = .10
  ) +
  geom_spaghetti(
    data = centers_tibble,
    aes(y = centers ,color = cluster),alpha = 10
  )+
  scale_color_manual(values = cluster_colors) +
  labs(x = "Time from seroconversion (months)",
       y = "log CD4 counts") +
  theme_classic() +
  theme(
    legend.position = "none",
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 12)
  )
```


```{r comparison-to-solu, echo = TRUE, message = FALSE}
# Results from my custom wrapper
#  tfb[366] on (-20,40) in basis representation:
#  using  2 FPCs 
# 1: (-20,7);(-19,7);(-18,7); ...
# 2: (-20,6);(-19,7);(-18,7); ...
# 3: (-20,7);(-19,7);(-18,7); ...
# 4: (-20,7);(-19,7);(-18,7); ...
# 5: (-20,7);(-19,7);(-18,7); ...
#     [....]   (361 not shown)


# Results from the solution in book turned into a tfd object after building the plot
# > tfd(Pred_mat, arg = seq)
# tfd[366] on (-20,40) based on 61 evaluations each
# interpolation by tf_approx_linear 
# [1]: (-20,7);(-19,7);(-18,7); ...
# [2]: (-20,6);(-19,6);(-18,6); ...
# [3]: (-20,7);(-19,7);(-18,7); ...
# [4]: (-20,7);(-19,7);(-18,7); ...
# [5]: (-20,7);(-19,7);(-18,7); ...
#     [....]   (361 not shown)


```

We can see from this panel, that although 2 FPCs comes very close to the solution in the textbook. 2 FPCs were enough to explain 99.5% of the variability.


# US all-cause excess and Covid-19 mortality

```{r setup-cv, echo = TRUE, message = FALSE}
# ─ Packages ───────────────────
# List of required packages
packages <- c(
  "refund",
  "tidyverse",
  "tidyfun",
  "scales",
  "usmap",
  "sf",
  "viridis",
  "factoextra",
  "mclust"
)

# Install missing packages
install_if_missing <- function(pkg) {
  if (!requireNamespace(pkg, quietly = TRUE)) {
    install.packages(pkg)
  }
}

# Install missing packages
invisible(lapply(packages, install_if_missing))

library(refund)    
library(tidyfun)   
library(tidyverse)  
library(scales)
library(usmap)
library(sf)
library(viridis)    
library(factoextra)
library(mclust)
```

```{r load-data-cv,  echo=TRUE, results='hide'}
# ─── Data ────────────────────────────
#Load data
data("COVID19", package = "refund")
names(COVID19)
##  [1] "US_weekly_mort"                      "US_weekly_mort_dates"               
##  [3] "US_weekly_mort_CV19"                 "US_weekly_mort_CV19_dates"          
##  [5] "US_weekly_excess_mort_2020"          "US_weekly_excess_mort_2020_dates"   
##  [7] "US_states_names"                     "US_states_population"               
##  [9] "States_excess_mortality"             "States_excess_mortality_per_million"
## [11] "States_CV19_mortality"               "States_CV19_mortality_per_million"

states <- COVID19$US_states_names
current_date <- COVID19$US_weekly_excess_mort_2020_dates
Wd <- COVID19$States_excess_mortality_per_million
reference_date <- as.Date("2020-01-01")
```

```{r helpers, include=TRUE}
# ──helpers───────────────────
# Converts calendar dates to numeric values 
# The tfd requires numeric values and not as dates values.
num_grid <- function(dates, ref = min(dates)) as.numeric(dates - ref)

num_grid_v2 <- function(dates, ref = as.Date("2020-01-01")) as.numeric(dates - ref)
tnum <- num_grid_v2(current_date)



tf_cluster_kmeans <- function(score_mat, K) {
  km <- kmeans(score_mat, centers = K)
  list(cluster = km$cluster, centers = km$centers)
}

tf_cluster_hclust <- function(score_mat, method = "ward.D2", K = 3) {
  hc <- hclust(dist(score_mat), method = method)
  list(cluster = cutree(hc, k = K), hc = hc)
}

# centres (matrix rows) -> tidyfun curves on a given grid
tf_centers_from_scores <- function(centers_mat, arggrid) {
  tfd(centers_mat, arg = arggrid)
}

# tidyfun helpers (join + plot)
tf_join_clusters_tf <- function(pred_tf, cluster_vec) {
  tibble(
    id      = seq_along(pred_tf),
    cluster = factor(cluster_vec),
    curve   = pred_tf
  )
}

tf_plot_clusters_tf <- function(cluster_tbl, centers_tbl) {
  ggplot() +
    ## highlight centres
    geom_spaghetti(
      data = centers_tbl,
      aes(y = curve, group = cluster),
      colour = "black", linewidth = 1
    ) +
    geom_spaghetti(
      data = centers_tbl,
      aes(y = curve, colour = cluster, group = cluster),
      linewidth = 1
    ) +
    ## individual subjects
    geom_spaghetti(
      data = cluster_tbl,
      aes(y = curve, colour = cluster, group = id),
      alpha = .15, linewidth = .7
    ) +
    scale_color_manual(
      values = c("darkred", "darkorange", "darkgreen"),
      name   = "Cluster"
    ) +
    labs(
      x = "Time from seroconversion (months)",
      y = "Log CD4 counts"
    ) +
    theme_minimal(base_size = 14)
}
```

```{r data-transformation-cv, include=TRUE,fig.width=9}
# ───Data Transformation ─────────────
# Organize highlighted the states and their curves

df_tibble <- tibble(
  state = states,
  mortality = tfd(Wd, arg = tnum)  
) %>%
  mutate(
    highlight = if_else(
      state %in% c("New Jersey","Louisiana","California","Maryland","Texas"),
      state, "Other"
    ),
    highlight = factor(highlight, levels = c("Other",
                                             "New Jersey","Louisiana","California","Maryland","Texas"))
  )
## # A tibble: 52 × 3
##    state                                                  mortality highlight 
##    <chr>                                                  <tfd_reg> <fct>     
##  1 Alabama               [1]: ( 3,  0.8);(10,  7.5);(17,-15.2); ... Other     
##  2 Alaska                [2]: ( 3,   -5);(10,   25);(17,    7); ... Other     
##  3 Arizona               [3]: ( 3,   -7);(10,    6);(17,    6); ... Other     
##  4 Arkansas              [4]: ( 3,   -7);(10,   28);(17,   -1); ... Other     
##  5 California            [5]: ( 3,    5);(10,    2);(17,    4); ... California
##  6 Colorado              [6]: ( 3,    3);(10,    7);(17,    4); ... Other     
##  7 Connecticut           [7]: ( 3,  0.3);(10,  0.8);(17,  3.1); ... Other     
##  8 Delaware              [8]: ( 3,   14);(10,   -1);(17,   -9); ... Other     
##  9 District of Columbia  [9]: ( 3,    3);(10,    8);(17,   49); ... Other     
## 10 Florida              [10]: ( 3,    6);(10,   10);(17,    8); ... Other     
## # ℹ 42 more rows

cols <- c(
  "Other"      = "grey85",   
  "New Jersey" = "darkseagreen3",  
  "Louisiana"  = "red",  
  "California" = "plum3",  
  "Maryland"   = "deepskyblue4",  
  "Texas"      = "salmon"   
)

# ─── Plot ────────────────────────────────
# Exploratory plots and analyses

ggplot(df_tibble) +
  geom_spaghetti(aes(y = mortality, colour = highlight, group = state),alpha =0.6) +
  scale_colour_manual(values = cols, name = "States") +
  scale_x_continuous(
    name = "Weeks starting January 2020",
    breaks = as.numeric(seq(reference_date, as.Date("2021-01-01"), by = "3 months") - reference_date),
    labels = format(seq(reference_date, as.Date("2021-01-01"), by = "3 months"), "%b %Y")
  ) +
  labs(y = "US states weekly excess deaths / million") +
  theme_minimal()
```


The curves are the weekly excess mortality per million residents for each U.S.
state. Five states receive special focus and are distinguished by color: New Jersey (green),
Louisiana (red), California (plum), Maryland (blue) and Texas (salmon).All remaining
states are in grey including Puerto Rico and District of Columbia.


Insigths: (i) many states exhibit similar mortality
curves over extended periods, as indicated by overlapping grey trajectories within the
interval of -50 to 100 excess deaths per million residents; (ii) New Jersey reached the
highest mortality peak among all states and territories, with over 300 deaths per million
residents; (iii) Louisiana and Maryland experienced sharp summer peaks, each exceeding
50 deaths per million residents; (iv) most states had elevated mortality in December, with
some states surpassing 100 deaths per million residents.

This visualization shows inherent similarities across curves in functional data analysis, which motivates the application of
clustering methods.




Mean and median calculations provide essential summary statistics and are a key part of exploratory data analysis, helping to numerically describe the central tendency of e
excess mortality rate per one million residents for several weeks across 52 states and territories.Thus a complement and help to interpret the visual patterns seen in the plot.

```{r , include=TRUE}
# ────────── Summary of Analysis──────────────────────
Wd_tfd <- tfd(Wd, arg = tnum)  
# Extract values at week 10 for all states
week10_vals <- Wd_tfd[, tnum[10]]

mean_week10   <- mean(week10_vals, na.rm = TRUE)
## [1] 3.302119
median_week10 <- median(week10_vals, na.rm = TRUE)
## [1] 2.626611
```

On March 7, 2020 (week 10), the excess mortality rate was 3.3 deaths per million on average, with a median of 2.63 deaths per million.

```{r , include=TRUE}
week10 <- Wd[, 10]
ind_out <- which.max(week10_vals)
# Get the name of that state
state_out <- states[ind_out]
val_out <- round(Wd_tfd[ind_out, tnum[6:14]], 1)
```

An outlier was observed in North Dakota on week 10. The state's excess mortality rates from weeks 6 to 14 were: 10.5, -17, 49.7, 10.5, 70.6, 39.2, 6.5, -30.1, -41.8 excess mortality.

Identify the five states with the highest weekly excess mortality rates on week 20.

```{r , include=TRUE}
# ---- Top 5 states at week 20 ----
vals20 <- Wd_tfd[, tnum[20]]
ord20  <- order(vals20)
topweek20 <- round(vals20[ord20][48:52], 1)
states_top_20 <- states[ord20][48:52]
```

For week 20, the five states with the highest excess mortality rates per million residents were the District of Columbia (136.1), Massachusetts (122.1), Delaware (114.5), Connecticut (106.3), and New Jersey (104.5), in descending order.

Identify the five states with the highest weekly excess mortality rates on week 30.

```{r , include=TRUE}
# ---- Top 5 states at week 30 ----
vals30 <- Wd_tfd[, tnum[30]]
ord30  <- order(vals30)
topweek30 <- round(vals30[ord30][48:52], 1)
states_top_30 <- states[ord30][48:52]
```

For week 30, the five states with the highest excess mortality rates per million residents were Mississippi (119.3), Arizona (107), Texas (88.8), Louisiana (87), and South Carolina (84.7), in descending order.

Identify the five states with the highest weekly excess mortality rates on week 40.

```{r , include=TRUE}
# ---- Top 5 states at week 40 ----
vals40 <- Wd_tfd[, tnum[40]]
ord40  <- order(vals40)
topweek40 <- round(vals40[ord40][48:52], 1)
states_top_40 <- states[ord40][48:52]
```

For week 40, the five states with the highest excess mortality rates per million residents were North Dakota (75.8), Arkansas (72.3), the District of Columbia (58.9), Missouri (58.4), and Wyoming (53.2), in descending order.

### K-means clustering of the functional data

```{r kmeans, include=TRUE, fig.width = 9, message = FALSE}
# ──────────────── K-means clustering of the functional data ──────────────────────────────

rownames(Wd) <- states
set.seed(1000)
# We are going to  run k-means 30 times and returns the best result
km <- kmeans(Wd, centers = 3, nstart = 30)
cl_ind <- km$cluster
cl_cen <- km$centers



##  ─── Build tidyfun objects ──────────────────────
pred_tf <- tfd(Wd, arg = tnum)

centers_tf <- tfd(cl_cen, arg = tnum)

# Create tibbles
cluster_tbl <- tf_join_clusters_tf(pred_tf, cl_ind)
centers_tbl <- tibble(
  cluster = factor(seq_len(nrow(cl_cen))),
  curve   = centers_tf
)

# Plot with corrected date handling
  tf_plot_clusters_tf(cluster_tbl, centers_tbl) +
  scale_color_manual(
    values =  c("#FF0000", "darkgreen", "#0000FF"),
    name   = "Cluster"
  ) +
  scale_x_continuous(
    breaks = function(x) {
      # Use 2020-01-01 as reference for quarterly breaks
      reference_date <- as.Date("2020-01-01")
      start_date <- reference_date  # Start from Jan 1, 2020
      end_date <- max(current_date)
      quarterly_dates <- seq(from = start_date, to = end_date, by = "3 months")
      # Convert to your numeric scale (days since 2020-01-01)
      as.numeric(quarterly_dates - reference_date)
    },
    labels = function(x) {
      # Convert back to dates using 2020-01-01 as reference
      reference_date <- as.Date("2020-01-01")
      d <- reference_date + x
      format(d, "%b %Y")
    },
    name = "Weeks starting January 2020"
  ) +
  labs(
    y = "Excess mortality per million"#,
    #title = "K-Means Clustering of State Excess-Mortality Curves"
  ) +
  theme_minimal(base_size = 14)

```

The curves are the weekly excess mortality per million resident for each U.S.
state and territories. Each state and territory is assigned to one of three groups using
kmeans clustering: Cluster 1 (red), Cluster 2 (dark green), and Cluster 3 (blue).The
cluster means are shown as thicker lines, matching the color of their respective clusters.

However, the algorithm is not guaranteed to find a unique solution. Different runs of
K-means may produce different clusters.So we ran 30 times and picked the best solution.
```{r k-us-plot, include = TRUE}
##  ─── US MAP PLOT ──────────────────────

# Color per group as per the book
colset <- c(rgb(1, 0, 0), rgb(0, 100/255, 0), rgb(0, 0, 1))
  

# Load state date which contains FIPS code
data("statepop")

# Create a data frame to plot based on the input requirement
state_cluster <- data.frame(full = names(cl_ind), cluster = unname(cl_ind))
data_cluster <- statepop %>%
  left_join(state_cluster, by = "full") %>%
  select(fips, cluster)
data_cluster$cluster <- as.factor(data_cluster$cluster)

# Make the US map
 plot_usmap(regions = "states", data = data_cluster, values = "cluster") +
  scale_fill_manual(name = "Cluster", values = colset) +
  labs(title = "") +
  theme(legend.position = "right", 
        plot.title = element_text(hjust = 0.5, face = "bold"))


# Start with default state centers
state_centers <- data.frame(
  state = tolower(state.name),
  lon = state.center$x,
  lat = state.center$y
)


# Modify locations for Alaska and Hawaii (inset display)
state_centers <- state_centers %>%
  mutate(
    lon = case_when(
      state == "alaska" ~ -116,
      state == "hawaii" ~ -103,
      TRUE ~ lon
    ),
    lat = case_when(
      state == "alaska" ~ 28,
      state == "hawaii" ~ 28,
      TRUE ~ lat
    )
  )

# Add Distric of Columbia and Puerto Rico
state_centers <- rbind(
  state_centers,
  data.frame(state = "district of columbia", lon = -77.03, lat = 38.89),
  data.frame(state = "puerto rico", lon = -108, lat = 30)
)



# Rename for join
state_centers <- state_centers %>%
  rename(region = state)
# ──────────────── Join Plot Data ───────────────────────────────

state_plot_df <- tibble(
  state   = tolower(states),
  curve   = pred_tf,
  cluster = factor(cl_ind)
) %>%
  left_join(state_centers, by = c("state" = "region"))

# ──────────────── US Map with Glyphs ───────────────────────────────

# Use usmap's state outlines
us_map_df <- us_map("states")



# Convert state_plot_df to sf object and transform to match us_map_df
 state_plot_sf <- state_plot_df %>%
  st_as_sf(coords = c("lon", "lat"), crs = 4326) %>%  # WGS84 (lat/lon)
  st_transform(st_crs(us_map_df)) %>%  # Transform to match us_map_df projection
  # Extract transformed coordinates
  mutate(
    x_proj = st_coordinates(.)[,1],
    y_proj = st_coordinates(.)[,2]
  ) %>%
  st_drop_geometry()  

ggplot() +
  # First add the map layer using geom_sf
  geom_sf(data = us_map_df,
          fill = "white",
          color = "black",
          size = 0.2) +
  # Add the functional data glyphs using transformed coordinates
  geom_capellini(data = state_plot_sf,
                 aes(x = x_proj, y = y_proj, tf = curve, colour = cluster),
                 width = 300000, height = 400000, line.linetype = 1) +  # Adjusted size for projected coords
  scale_color_manual(values = c("#FF0000", "darkgreen", "#0000FF"),
                     name = "Cluster") +
  coord_sf() +
  theme_minimal() +
  labs(#title = "US States Excess Mortality Curves with Cluster Colors",
       # or just "Longitude"
       x = "Longitude (°)",  
       ,# or just "Latitude"
       y = "Latitude (°)" )

```

The first figure is U.S. map of the three estimated clusters for weekly excess mortality rates in
2020. Each state and territory is assigned to one of three groups using kmeans clustering:
Cluster 1 (red), Cluster 2 (dark green), and Cluster 3 (blue).


The second map is U.S. map showing the curve of each state and territory with the three es-
timated clusters for weekly excess mortality rates in 2020. Each state and territory is
assigned to one of three groups using kmeans clustering: Cluster 1 (red), Cluster 2 (dark
green), and Cluster 3 (blue).

### Hierarchical clustering of functional data

```{r data-process-hc, warning = FALSE, include = TRUE, fig.width = 8, fig.height = 7}
# ── Hierarchical clustering of functional data ───────────────

# Calculate the matrix of distances
dist_matrix <- dist(Wd[,])^2

# Hierarchical clustering on the square Euclidian distances
hc <- hclust(dist_matrix, method = "ward.D2")

# ─── plot  ───────────

 fviz_dend(hc,
                             k = 5,
                             rect = TRUE,  
                             rect_fill = FALSE, 
                             k_colors = c("#E69A8DFF", "#F6D55C", "#2A9D8F", "#5F4B8BFF", "#ee7600"),
                             lwd = 1,         
                             cex = 0.5,         
                             #main = "Hierarchical clustering on the square Euclidian distances",
                             xlab = "Observations",
                             ylab = "Distance (Ward.D2)",
                             ggtheme = theme_minimal()) +
  scale_y_continuous(labels = function(x) {
    ifelse(x == 0, "0", paste0(scales::comma(x/1000), "K"))
  })
```

Hierarchical clustering of weekly excess mortality rates in 2020 across U.S.
states and territories using Ward.D2 linkage on squared Euclidean distances. The dendrogram is cut at K = 5 clusters , producing five distinct groups indicated by different colors:
cluster 1 (salmon), cluster 2 (yellow), cluster 3 (green), cluster 4 (violet) and cluster 5
(dark orange).

```{r heatmap, include=TRUE, fig.width=7,fig.height=7}
# ─── Hierarchical clustering ────────────────────
cluster_assignments <- cutree(hc, k = 5)

rownames(Wd) <- states

# the 52 states in dendrogram order
state_order <- rownames(Wd)[hc$order]

# for each state, its position in that order
row_order_vec  <- match(states, state_order)

cluster_colors <- c("#E69A8DFF", "#F6D55C", "#2A9D8F", "#5F4B8BFF", "#ee7600")
state_colors <- cluster_colors[cluster_assignments[states]]

# ─── Build tidyfun tibble ───────────────────────────────────────────────────
#this results in a tibble where each state has its own curve
df_tf <- tibble(
  state = states,
  # wrap  52-length vectors as tfd as per usual
  mortality = tfd(Wd, arg = tnum),   
  # numeric: 1–52 in cluster order
  row_order = row_order_vec,
  cluster = cluster_assignments[states],  # Add cluster assignment
  state_color = state_colors              # Add state color
)
## # A tibble: 52 × 5
##    state                                             mortality row_order cluster
##    <chr>                                             <tfd_reg>     <int>   <int>
##  1 Alabama          [1]: ( 3,  0.8);(10,  7.5);(17,-15.2); ...        19       1
##  2 Alaska           [2]: ( 3,   -5);(10,   25);(17,    7); ...         5       2
##  3 Arizona          [3]: ( 3,   -7);(10,    6);(17,    6); ...        18       1
##  4 Arkansas         [4]: ( 3,   -7);(10,   28);(17,   -1); ...        36       1
##  5 California       [5]: ( 3,    5);(10,    2);(17,    4); ...        33       1
##  6 Colorado         [6]: ( 3,    3);(10,    7);(17,    4); ...        45       3
##  7 Connecticut      [7]: ( 3,  0.3);(10,  0.8);(17,  3.1); ...        40       3
##  8 Delaware         [8]: ( 3,   14);(10,   -1);(17,   -9); ...        51       3
##  9 District of Co…  [9]: ( 3,    3);(10,    8);(17,   49); ...        39       3
## 10 Florida         [10]: ( 3,    6);(10,   10);(17,    8); ...        15       1
## # ℹ 42 more rows
## # ℹ 1 more variable: state_color <chr>

# ─── Plot  ───────────────────────────────────────────────────


# Replicate the original's color strategy
breaks_orig <- c(-50, seq(-40, 130, by = 1), 200, 250, 300)
colors_orig <- viridis::plasma(length(breaks_orig))

 gglasagna(
  df_tf,
  tf = mortality,
  order = row_order,
  label = state
) +
  scale_fill_gradientn(
    colors = colors_orig,
    values = scales::rescale(breaks_orig),
    breaks = c(-50, 0, 50, 100, 150, 200, 250, 300),
    limits = c(-50, 300),
    name = "EMR"
  ) +
  guides(color = "none") +  
  scale_x_continuous(
    name   = "Weeks starting january 2020",
    breaks = num_grid(current_date),
    labels = seq_along(current_date)
  )+
  labs(
    #title = "Heatmap of 2020 Weekly Excess Mortality\nStates ordered by hierarchical clustering",
    caption = ""
  ) +
  theme_minimal(base_size = 12) +
  theme(
       axis.text.y = element_text(
      size = 6, 
      color = df_tf$state_color[order(df_tf$row_order)]
    ),
    axis.text.x = element_text(size = 6, angle = 90, vjust = 0.5, hjust=1),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank()
  )



df_tf <- tibble(
  state = states,
  # wrap  52-length vectors as tfd as per usual
  mortality = tfd(Wd, arg = tnum),   
  # numeric: 1–52 in cluster order
  row_order = row_order_vec
)
```
Heatmap of weekly excess mortality rates across U.S. states and two territories
in the first 52 weeks of 2020.


Insigths: cluster 1 (yellow) represents states with consistently low excess mortality
rates throughout the year. Cluster 3 (salmon) includes states with mostly high excess mortality rates at the end of the year. Cluster 5 (green) consists of states with excess mortality rates peaking in the summer and at the end of the year.
```{r hc-map, include = TRUE}
cut_wardd2 <- cutree(hc, k = 5)

# Get the order of clusters as they appear in the dendrogram (left to right)
dend_order <- hc$order
cluster_first_appearance <- sapply(1:5, function(k) {
  which(dend_order %in% which(cut_wardd2 == k))[1]
})
cluster_reorder <- rank(cluster_first_appearance)

# Relabel clusters based on dendrogram order
relabeled_clusters <- cluster_reorder[cut_wardd2]

clust.col <- c("#E69A8DFF", "#F6D55C", "#2A9D8F", "#5F4B8BFF", "#ee7600")
#cluster_names <- c("Early Peak", "Sustained High", "Late Peak", "Moderate", "Low Impact")


state_cluster <- data.frame(
  full = names(cut_wardd2), 
  cluster = relabeled_clusters#,
  #cluster_name = cluster_names[relabeled_clusters]
)

## load state date which contains FIPS code
data("statepop")
data_cluster <- statepop %>%
  left_join(state_cluster, by = "full") %>%
  select(fips, cluster#, cluster_name
         ) %>%
  mutate(cluster = as.factor(cluster))


# ─── Plot  ───────────────────────────────────────────────────

 plot_usmap(regions = "states", data = data_cluster, values = "cluster") +
  scale_fill_manual(
    name = "Cluster", 
    values = clust.col#,
    #labels = cluster_names
  ) +
  labs(
    #title = "COVID-19 Excess Mortality Clusters",
    #subtitle = "States grouped by temporal mortality patterns"
  ) +
  theme(
    legend.position = "bottom",
    legend.title = element_text(size = 12, face = "bold"),
    legend.text = element_text(size = 10),
    plot.title = element_text(hjust = 0.5, face = "bold", size = 16),
    plot.subtitle = element_text(hjust = 0.5, size = 12)
  ) +
  guides(fill = guide_legend(nrow = 1))
```

U.S. map of the five estimated clusters for weekly excess mortality rates in 2020
using Ward.D2 linkage on squared Euclidean distances. Five distinct groups indicated by
different colors: cluster 1 (salmon), cluster 2 (yellow), cluster 3 (green), cluster 4 (violet)
and cluster 5 (dark orange).

```{r glyphmap-hc, include = TRUE}
# Relabel clusters for consistent order
dend_order <- hc$order
cluster_first_appearance <- sapply(1:5, function(k) {
  which(dend_order %in% which(cut_wardd2 == k))[1]
})
cluster_reorder <- rank(cluster_first_appearance)
relabeled_clusters <- cluster_reorder[cut_wardd2]

# Create cluster mapping
# Fix 1: Make sure both data frames have lowercased state names
state_cluster <- tibble(
  state = tolower(states),  # ⬅️ lowercase to match df_tf
  cluster = factor(relabeled_clusters)
)



state_centers <- data.frame(
  state = tolower(state.name),
  lon = state.center$x,
  lat = state.center$y
)

# Adjust Hawaii and Alaska for inset layout
state_centers <- state_centers %>%
  mutate(
    lon = case_when(
      state == "alaska" ~ -116,
      state == "hawaii" ~ -103,
      TRUE ~ lon
    ),
    lat = case_when(
      state == "alaska" ~ 28,
      state == "hawaii" ~ 28,
      TRUE ~ lat
    )
  )

# Add DC and Puerto Rico
state_centers <- rbind(
  state_centers,
  data.frame(state = "district of columbia", lon = -77.03, lat = 38.89),
  data.frame(state = "puerto rico", lon = -108, lat = 30)
) %>%
  rename(region = state)



# Functional curves already in df_tf
# Merge with cluster info and centroid coordinates
state_plot_df <- df_tf %>%
  mutate(state = tolower(state)) %>%
  left_join(state_cluster, by = c("state")) %>%
  left_join(state_centers, by = c("state" = "region"))




# Base map
us_map_df <- usmap::us_map("states")

# Convert to sf and project to match US map projection
state_plot_sf <- state_plot_df %>%
  st_as_sf(coords = c("lon", "lat"), crs = 4326) %>%  # WGS84
  st_transform(st_crs(us_map_df)) %>%
  mutate(
    x_proj = st_coordinates(.)[,1],
    y_proj = st_coordinates(.)[,2]
  ) %>%
  st_drop_geometry()




cluster_colors <- c("#E69A8DFF", "#F6D55C", "#2A9D8F", "#5F4B8BFF", "#ee7600")

 ggplot() +
  geom_sf(data = us_map_df,
          fill = "white",
          color = "black",
          size = 0.2) +
  
  geom_capellini(data = state_plot_sf,
                 aes(x = x_proj, y = y_proj, tf = mortality, colour = cluster),
                 width = 300000, height = 400000,
                 line.linetype = 1, alpha = 2) +
  
  scale_color_manual(values = cluster_colors, name = "Cluster") +
  coord_sf() +
  theme_minimal(base_size = 12) +
  labs(
    #title = "US States Excess Mortality Curves with Cluster Colors",
    x = "Longitude (°)",
    y = "Latitude (°)"
  ) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    legend.position = "right"
  )
```


U.S. map showing the curve of each state and territory with the five es-
timated clusters for weekly excess mortality rates in 2020 using Ward.D2 linkage on
squared Euclidean distances. Five distinct groups indicated by different colors: cluster
1 (salmon), cluster 2 (yellow), cluster 3 (green), cluster 4 (violet) and cluster 5 (dark
orange).

### Distributional clustering

```{r db-cl, include=TRUE}
# ─── Distributional clustering ───────────────────────────────────────────────────

# Set color palette
cluster_colors <- c("#E69A8DFF", "#F6D55C", "#2A9D8F", "#5F4B8BFF")

# Center and scale data
X_scaled <- scale(Wd) %>% as.data.frame()

# Fit Gaussian Mixture Model using BIC
bic <- mclustBIC(X_scaled)
# Bayesian Information Criterion (BIC): 
#         EII       VII       EEI       VEI       EVI       VVI
# 1 -7830.529 -7830.529 -8032.042 -8032.042 -8032.042 -8032.042
# 2 -7609.035 -7612.616 -7774.047 -7777.983 -7778.249 -7778.502
# 3 -7480.743 -7389.161 -7533.148 -7475.997 -7688.448 -7577.282
# 4 -7372.236 -7257.856 -7381.381 -7320.383 -7772.885 -7625.539
# 5 -7358.711        NA -7359.944        NA        NA        NA
# 6 -7391.220        NA -7402.952        NA        NA        NA
# 7 -7410.073        NA -7485.683        NA        NA        NA
# 8 -7408.936        NA -7400.588        NA        NA        NA
# 9 -7428.796        NA -7439.884        NA        NA        NA
# 
# Top 3 models based on the BIC criterion: 
#     VII,4     VEI,4     EII,5 
# -7257.856 -7320.383 -7358.711 
gmm_model <- Mclust(X_scaled, x = bic)
#'Mclust' model object: (VII,4) 
clusters <- gmm_model$classification

# Merge clustering results with state population data
state_clusters <- data.frame(full = names(cut_wardd2), cluster = clusters)

data_cluster <- statepop %>%
  left_join(state_clusters, by = "full") %>%
  mutate(cluster = factor(cluster)) %>%
  select(fips, cluster)

# Plot the US map
  plot_usmap(regions = "states", data = data_cluster, values = "cluster") +
  scale_fill_manual(name = "Cluster", values = cluster_colors) +
  labs(title = "") +
  theme(
    legend.position = "right",
    plot.title = element_text(hjust = 0.5, face = "bold")
  )


# Print the map with adjusted margins
par(mar = c(4, 4, 1, 1))

```

U.S. map of the four estimated clusters for weekly excess mortality rates in
2020 using Gaussian mixture model. Four distinct groups indicated by different colors:
cluster 1 (salmon), cluster 2 (yellow), cluster 3 (green), cluster 4 (violet).
```{r db-plot, include=TRUE}
library(mclust)

X <- scale(Wd)

# Get BIC and fit GMM
BIC <- mclustBIC(X)
mod <- Mclust(X, x = BIC)

# Get 4-cluster result
res <- mod$classification

# Use same state name vector and lowercase for joining
state_cluster <- tibble(
  state = tolower(names(res)),
  cluster = factor(res)
)


state_centers <- data.frame(
  state = tolower(state.name),
  lon = state.center$x,
  lat = state.center$y
) %>%
  mutate(
    lon = case_when(
      state == "alaska" ~ -116,
      state == "hawaii" ~ -103,
      TRUE ~ lon
    ),
    lat = case_when(
      state == "alaska" ~ 28,
      state == "hawaii" ~ 28,
      TRUE ~ lat
    )
  ) %>%
  rbind(
    data.frame(state = "district of columbia", lon = -77.03, lat = 38.89),
    data.frame(state = "puerto rico", lon = -108, lat = 30)
  ) %>%
  rename(region = state)


df_tf <- tibble(
  state = tolower(states),
  mortality = tfd(Wd, arg = tnum)
)


state_plot_df <- df_tf %>%
  left_join(state_cluster, by = "state") %>%
  left_join(state_centers, by = c("state" = "region"))



library(sf)
library(usmap)

us_map_df <- usmap::us_map("states")

state_plot_sf <- state_plot_df %>%
  st_as_sf(coords = c("lon", "lat"), crs = 4326) %>%
  st_transform(st_crs(us_map_df)) %>%
  mutate(
    x_proj = st_coordinates(.)[,1],
    y_proj = st_coordinates(.)[,2]
  ) %>%
  st_drop_geometry()



colset <- c("#E69A8DFF", "#F6D55C", "#2A9D8F", "#5F4B8BFF")

ggplot() +
  geom_sf(data = us_map_df, fill = "white", color = "black", size = 0.2) +
  
  geom_capellini(
    data = state_plot_sf,
    aes(x = x_proj, y = y_proj, tf = mortality, colour = cluster),
    width = 300000, height = 400000, line.linetype = 1
  ) +
  
  scale_color_manual(values = colset, name = "Cluster") +
  coord_sf() +
  theme_minimal(base_size = 12) +
  labs(
    #title = "US States: Model-Based Clustering of Excess Mortality Curves",
    #subtitle = "Gaussian Mixture Model (Mclust) with 4 clusters",
    x = "Longitude", y = "Latitude"
  ) +
  theme(
    legend.position = "right",
    plot.title = element_text(hjust = 0.5, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5)
  )
```




U.S. map showing the curve of each state and territory with the four estimated clusters for weekly excess mortality rates in 2020 using using Gaussian mixture
model. Four distinct groups indicated by different colors: cluster 1 (salmon), cluster 2
(yellow), cluster 3 (green), cluster 4 (violet)